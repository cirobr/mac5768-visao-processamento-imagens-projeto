{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MAC 5768 - Visão e Processamento de Imagens\n",
    "\n",
    "Segundo Semestre - 2020\n",
    "\n",
    "Equipe:\n",
    "\n",
    "Ciro B Rosa - ciro.rosa@alumni.usp.br\n",
    "Josilton Sousa - josilton.sousa@gmail.com\n",
    "\n",
    "Projeto de elaboração de tarefas do curso de Visão e Processamento de Imagens.\n",
    "\n",
    "Fase 3 - Parte 2 - Entrega em 22/01/2021\n",
    "\n",
    "Objetivos:\n",
    "\n",
    "* A partir das imagens segmentadas manualmente (dataset \"bboxManual\" gerado no EP 3.1):\n",
    "- Normalizar todas as imagens para um tamanho padrão\n",
    "- Dividir esse dataset em dois sendo um de treino (75%) e outro de testes (25% das imagens)\n",
    "\n",
    "* A partir do trainset, executar classificação de imagens cumprindo as seguintes etapas:\n",
    "- Geração de autovetores (PCA), com redução do tamanho do array de features\n",
    "- Geração do Feature Vector: Projeção das imagens originais sobre o novo conjunto de autovetores\n",
    "- Geração do algoritmo de classificação (SVM)\n",
    "- Classificar o Testset, com base no Feature Vector\n",
    "- Classificar as imagens do dataset bboxOtsu, com base no mesmo Feature Vector\n",
    "\n",
    "Após cada classificação, um relatório é gerado e analisado.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " Após a divisão dos dataset, sbmetar as imagens em um algoritmo para análise de Componentes Principais (PCA).\n",
    " * Após análise dos componentes principais submeter a um classificador e gerar um relatório com os resultados \n",
    " \n",
    "\n",
    "Leitura e Normalização de imagens.\n",
    "   Durante a leitura e processamento das imagens que foram extraídas as áreas de interesse (ROI) geradas no EP anterior, ocorreram alguns problemas durante o processamentos das imagens. Após analise, identificamos que as imagens não estavam com o mesmo tamanho.\n",
    "   Descobrimos que o problema estava na forma dos objetos, ou seja, como havia objetos de tamanhos diferentes (chave, caneca, garfo, caderno etc.), ao gerar o ROI as imagens ficavam com tamanhos diferentes. E isso era um problema para o processamento pois para analise de PCA as imagens devem ter o mesmo tamanho.\n",
    "   Para corrigir esse problema tivemos que normalizar as imagens antes de submeter ao PCA. \n",
    "    \n",
    "    O código a baixo realiza a leitura das imagens que estão no Dataset \"bboxManual\" (que foras as imagens que passou por uma limiarrização manual no EP anterior) e normalizadas com a função \"resize\" do pacote Opencv. As imagens foram normalizadas para as dimensões de 100 x 100.\n",
    "    Em seguida é criado a divisão do Dataset em dois. Um de teste e outro para treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização de tamanho e divisão do dataset Ground Truth em Trainset e Testset\n",
    "\n",
    "Com a ajuda do código a seguir, o dataset bboxManual contendo 160 fotos segmentadas manualmente normalizado para um tamanho padrão (escolhido como 100 x 100 neste projeto), e posteriormente dividido em dois blocos de forma aleatória: trainset (75% das fotos) e testset (25%). O trainset será utilizado para treinar o algoritmo de classificação, enquanto que o testset será usado para medição da performance do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sequencia   objeto tipo_obj   fundo  iluminacao transformacao responsavel  \\\n",
      "0          3  alicate        a  branco  indoor dia   bbox manual        Ciro   \n",
      "1          3    chave        a  branco  indoor dia   bbox manual        Ciro   \n",
      "2          3   caneta        a  branco  indoor dia   bbox manual        Ciro   \n",
      "3          3    livro        a  branco  indoor dia   bbox manual        Ciro   \n",
      "4          3  caderno        a  branco  indoor dia   bbox manual        Ciro   \n",
      "\n",
      "    arquivo  \n",
      "0  1098.jpg  \n",
      "1  1101.jpg  \n",
      "2  1104.jpg  \n",
      "3  1107.jpg  \n",
      "4  1110.jpg   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from cv2 import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# ler metadados segmentação manual\n",
    "pasta1 = \"./bboxManual/\"\n",
    "metafile1 = \"grade.csv\"\n",
    "filename1 = pasta1 + metafile1\n",
    "df1 = pd.read_csv(filename1, sep=\";\")\n",
    "print(df1.head(5), \"\\n\")\n",
    "\n",
    "\n",
    "# ler fotos em uma lista\n",
    "fotos1 = []\n",
    "for foto in df1[\"arquivo\"]:\n",
    "    fullname1 = pasta1 + foto\n",
    "    img1 = io.imread(fullname1)\n",
    "    fotos1.append(img1)\n",
    "\n",
    "    \n",
    "# normalizar fotos para dimensão única\n",
    "d = 100\n",
    "dim = (d, d)\n",
    "fotos2 = [resize(img1, dim) for img1 in fotos1]\n",
    "\n",
    "\n",
    "# criar arrays de predictors e outcomes\n",
    "X = [f2.flatten() for f2 in fotos2]\n",
    "y = df1[\"objeto\"]\n",
    "\n",
    "# dividir os dados em trainset e testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração do Feature Vector\n",
    "\n",
    "Uma vez realizado a normalização das imagens e criado os datasets de treinamento e testes, as imagens foram submetidas ao processo de análise de Componentes Principais (PCA). Este processo demanda a definição de cetos parâmetros, sendo o proncipal o número de components principais (n_components). A equipe decidiu trabalhar com n_components = 110, o que implica em uma redução de features de treinamento de 10000 (= 100 x 100) para 110.\n",
    "\n",
    "Como resultado do PCA, um conjunto de autovetores é gerado. O próximo passo é então projetar as imagens e calcular suas coordenadas para este novo conjunto de autovetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA - Extracting eigenvectors\n",
      "done in 0.703s\n",
      "PCA - Projecting to new orthonormal coordinates\n",
      "done in 0.026s\n"
     ]
    }
   ],
   "source": [
    "# calcular PCA\n",
    "n_components = 110\n",
    "\n",
    "print(\"PCA - Extracting eigenvectors\")\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components=n_components,\n",
    "          svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "h = d\n",
    "w = d\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "print(\"PCA - Projecting to new orthonormal coordinates\")\n",
    "t0 = time()\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do modelo de classificação\n",
    "\n",
    "Após a redução de features/predictors do set de imagens para aqueles mais relevantes, é gerado o algoritmo de classificação com o SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Fitting the classifier to the training set\n",
      "done in 0.879s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, class_weight='balanced', gamma=0.005)\n"
     ]
    }
   ],
   "source": [
    "# treinar o modelo com SVM\n",
    "print(\"SVM - Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf',\n",
    "                       class_weight='balanced'),\n",
    "                   param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste do modelo de classificação com o Testset\n",
    "\n",
    "O código a seguir utiliza o modelo gerado a partir do Trainset e classifica as 25% do total de imagens identificadas como Testset. Em seguida, um relatório de desempenho (classification report/ confusion matrix) é gerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes on the test set\n",
      "done in 0.002s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     alicate       1.00      1.00      1.00         3\n",
      "     caderno       0.20      0.33      0.25         3\n",
      "      caneca       0.83      1.00      0.91         5\n",
      "      caneta       0.71      0.83      0.77         6\n",
      "       chave       1.00      0.67      0.80         3\n",
      "      colher       1.00      0.62      0.77         8\n",
      "        faca       0.50      0.50      0.50         4\n",
      "       garfo       1.00      0.67      0.80         3\n",
      "       livro       0.50      0.60      0.55         5\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.75      0.69      0.70        40\n",
      "weighted avg       0.76      0.70      0.71        40\n",
      "\n",
      "[[3 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 2]\n",
      " [0 0 5 0 0 0 0 0 0]\n",
      " [0 0 0 5 0 0 0 0 1]\n",
      " [0 0 1 0 2 0 0 0 0]\n",
      " [0 1 0 1 0 5 1 0 0]\n",
      " [0 1 0 1 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 1 2 0]\n",
      " [0 2 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# avaliar o modelo com o testset\n",
    "print(\"Predicting classes on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Confusion Matrix acima mostrou um desempenho satisfatório na identificação das seguints classes: alicate, caneca, caneta, chave, colher, grafo. As precisões ficaram entre 0,71 e 1,00.\n",
    "\n",
    "Merece destaque a classificação de alicates: tanto a identificação positiva (precision) quanto a identificação negativa (recall) obtiveram escores máximos.\n",
    "\n",
    "Além disso, o escore balanceado \"f1-score\" indica classificação bastante deficiente para caderno (0,25). Facas e livros apresentaram desempenho do f1-score ao redor de 0,50. Demais itens obtiveram um escore balanceado relativamente alto (acima de 0,77).\n",
    "\n",
    "Por fim, o \"Overall Accuracy\" do dataset \"ground truth\" ficou em 0,70.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação da segmentação automática\n",
    "\n",
    "Como última etapa do projeto, classificamos o dataset \"bboxOtsu\", o qual foi segmentado de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4531896acf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfoto\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arquivo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfullname1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpasta1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfoto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullname1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfotos1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                (plugin, kind))\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# Otherwise error in close hide the real error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Process results and clean request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mac/lib/python3.8/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Close open files that we know of (and are responsible for)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uri_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mURI_FILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###\n",
    "### avaliar o modelo com o dataset \"bboxOtsu\"\n",
    "###\n",
    "\n",
    "# ler metadados segmentação Otsu\n",
    "pasta1 = \"./bboxOtsu/\"\n",
    "metafile1 = \"grade.csv\"\n",
    "filename1 = pasta1 + metafile1\n",
    "df1 = pd.read_csv(filename1, sep=\";\")\n",
    "#print(df1.head(5), \"\\n\")\n",
    "\n",
    "\n",
    "# ler fotos em uma lista\n",
    "fotos1 = []\n",
    "for foto in df1[\"arquivo\"]:\n",
    "    fullname1 = pasta1 + foto\n",
    "    img1 = io.imread(fullname1)\n",
    "    fotos1.append(img1)\n",
    "\n",
    "    \n",
    "# normalizar fotos para dimensão única\n",
    "d = 100\n",
    "dim = (d, d)\n",
    "fotos2 = [resize(img1, dim) for img1 in fotos1]\n",
    "\n",
    "\n",
    "# criar arrays de predictors e outcomes\n",
    "X = [f2.flatten() for f2 in fotos2]\n",
    "y = df1[\"objeto\"]\n",
    "\n",
    "\n",
    "# calcular PCA\n",
    "n_components = 110\n",
    "\n",
    "print(\"PCA - Extracting eigenvectors\")\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components=n_components,\n",
    "          svd_solver='randomized',\n",
    "          whiten=True).fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "h = d\n",
    "w = d\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "print(\"PCA - Projecting to new orthonormal coordinates\")\n",
    "t0 = time()\n",
    "\n",
    "X_pca = pca.transform(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "# avaliar o modelo com o dataset completo bboxOtsu\n",
    "print(\"Predicting classes on bbox Otsu\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
