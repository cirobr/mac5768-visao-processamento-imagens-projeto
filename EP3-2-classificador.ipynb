{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MAC 5768 - Visão e Processamento de Imagens\n",
    "\n",
    "Segundo Semestre - 2020\n",
    "\n",
    "Equipe:\n",
    "\n",
    "Ciro B Rosa - ciro.rosa@alumni.usp.br\n",
    "Josilton Sousa - josilton.sousa@gmail.com\n",
    "\n",
    "Projeto de elaboração de tarefas do curso de Visão e Processamento de Imagens.\n",
    "\n",
    "Fase 3 - Parte 2 - Entrega em 22/01/2021\n",
    "\n",
    "Objetivos:\n",
    "\n",
    "* A partir das imagens segmentadas manualmente (dataset \"bboxManual\" gerado no EP 3.1):\n",
    "- Normalizar todas as imagens para um tamanho padrão\n",
    "- Dividir esse dataset em dois sendo um de treino (75%) e outro de testes (25% das imagens)\n",
    "\n",
    "* A partir do trainset, executar classificação de imagens cumprindo as seguintes etapas:\n",
    "- Geração de autovetores (PCA), com redução do tamanho do array de features\n",
    "- Geração do Feature Vector: Projeção das imagens originais sobre o novo conjunto de autovetores\n",
    "- Geração do algoritmo de classificação (SVM)\n",
    "- Classificar o Testset, com base no Feature Vector\n",
    "- Classificar as imagens do dataset bboxOtsu, com base no mesmo Feature Vector\n",
    "\n",
    "Após cada classificação, um relatório é gerado e analisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização de tamanho e divisão do dataset Ground Truth em Trainset e Testset\n",
    "\n",
    "Com a ajuda do código a seguir, o dataset bboxManual contendo 160 fotos segmentadas manualmente normalizado para um tamanho padrão (escolhido como 100 x 100 neste projeto), e posteriormente dividido em dois blocos de forma aleatória: trainset (75% das fotos) e testset (25%). O trainset será utilizado para treinar o algoritmo de classificação, enquanto que o testset será usado para medição da performance do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sequencia   objeto tipo_obj   fundo  iluminacao transformacao responsavel  \\\n",
      "0          3  alicate        a  branco  indoor dia   bbox manual        Ciro   \n",
      "1          3    chave        a  branco  indoor dia   bbox manual        Ciro   \n",
      "2          3   caneta        a  branco  indoor dia   bbox manual        Ciro   \n",
      "3          3    livro        a  branco  indoor dia   bbox manual        Ciro   \n",
      "4          3  caderno        a  branco  indoor dia   bbox manual        Ciro   \n",
      "\n",
      "    arquivo  \n",
      "0  1098.jpg  \n",
      "1  1101.jpg  \n",
      "2  1104.jpg  \n",
      "3  1107.jpg  \n",
      "4  1110.jpg   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from cv2 import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# ler metadados segmentação manual\n",
    "pasta1 = \"./bboxManual/\"\n",
    "metafile1 = \"grade.csv\"\n",
    "filename1 = pasta1 + metafile1\n",
    "df1 = pd.read_csv(filename1, sep=\";\")\n",
    "print(df1.head(5), \"\\n\")\n",
    "\n",
    "\n",
    "# ler fotos em uma lista\n",
    "fotos1 = []\n",
    "for foto in df1[\"arquivo\"]:\n",
    "    fullname1 = pasta1 + foto\n",
    "    img1 = io.imread(fullname1)\n",
    "    fotos1.append(img1)\n",
    "\n",
    "    \n",
    "# normalizar fotos para dimensão única\n",
    "d = 100\n",
    "dim = (d, d)\n",
    "fotos2 = [resize(img1, dim) for img1 in fotos1]\n",
    "\n",
    "\n",
    "# criar arrays de predictors e outcomes\n",
    "X = [f2.flatten() for f2 in fotos2]\n",
    "y = df1[\"objeto\"]\n",
    "\n",
    "# dividir os dados em trainset e testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração do Feature Vector\n",
    "\n",
    "Uma vez realizado a normalização das imagens e criado os datasets de treinamento e testes, as imagens foram submetidas ao processo de análise de Componentes Principais (PCA). Este processo demanda a definição de cetos parâmetros, sendo o proncipal o número de components principais (n_components). A equipe decidiu trabalhar com n_components = 110, o que implica em uma redução de features de treinamento de 10000 (= 100 x 100) para 110.\n",
    "\n",
    "Como resultado do PCA, um conjunto de autovetores é gerado. O próximo passo é então projetar as imagens e calcular suas coordenadas para este novo conjunto de autovetores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA - Extracting eigenvectors\n",
      "done in 0.303s\n",
      "PCA - Projecting to new orthonormal coordinates\n",
      "done in 0.029s\n"
     ]
    }
   ],
   "source": [
    "# calcular PCA\n",
    "n_components = 110\n",
    "\n",
    "print(\"PCA - Extracting eigenvectors\")\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components=n_components,\n",
    "          svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "h = d\n",
    "w = d\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "print(\"PCA - Projecting to new orthonormal coordinates\")\n",
    "t0 = time()\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do modelo de classificação\n",
    "\n",
    "Após a redução de features/predictors do set de imagens para aqueles mais relevantes, é gerado o algoritmo de classificação com o SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Fitting the classifier to the training set\n",
      "done in 0.911s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, class_weight='balanced', gamma=0.005)\n"
     ]
    }
   ],
   "source": [
    "# treinar o modelo com SVM\n",
    "print(\"SVM - Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(SVC(kernel='rbf',\n",
    "                       class_weight='balanced'),\n",
    "                   param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste do modelo de classificação com o Testset\n",
    "\n",
    "O código a seguir utiliza o modelo gerado a partir do Trainset e classifica as 25% do total de imagens identificadas como Testset. Em seguida, um relatório de desempenho (classification report/ confusion matrix) é gerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes on the test set\n",
      "done in 0.002s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     alicate       1.00      1.00      1.00         3\n",
      "     caderno       0.20      0.33      0.25         3\n",
      "      caneca       0.83      1.00      0.91         5\n",
      "      caneta       0.71      0.83      0.77         6\n",
      "       chave       1.00      0.67      0.80         3\n",
      "      colher       1.00      0.62      0.77         8\n",
      "        faca       0.50      0.50      0.50         4\n",
      "       garfo       1.00      0.67      0.80         3\n",
      "       livro       0.50      0.60      0.55         5\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.75      0.69      0.70        40\n",
      "weighted avg       0.76      0.70      0.71        40\n",
      "\n",
      "[[3 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 2]\n",
      " [0 0 5 0 0 0 0 0 0]\n",
      " [0 0 0 5 0 0 0 0 1]\n",
      " [0 0 1 0 2 0 0 0 0]\n",
      " [0 1 0 1 0 5 1 0 0]\n",
      " [0 1 0 1 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 1 2 0]\n",
      " [0 2 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# avaliar o modelo com o testset\n",
    "print(\"Predicting classes on the test set\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Confusion Matrix acima mostrou um desempenho satisfatório na identificação das seguints classes: alicate, caneca, caneta, chave, colher, grafo. As precisões ficaram entre 0,71 e 1,00.\n",
    "\n",
    "Merece destaque a classificação de alicates: tanto a identificação positiva (precision) quanto a identificação negativa (recall) obtiveram escores máximos.\n",
    "\n",
    "Por outro lado, o escore balanceado \"f1-score\" indica classificação bastante deficiente para caderno (0,25). Facas e livros apresentaram desempenho do f1-score ao redor de 0,50. Demais itens obtiveram um escore balanceado relativamente alto (acima de 0,77).\n",
    "\n",
    "Por fim, o \"Overall Accuracy\" do dataset \"ground truth\" ficou em 0,70.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificação da segmentação automática\n",
    "\n",
    "Como última etapa do projeto, classificamos o dataset \"bboxOtsu\", o qual foi segmentado de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA - Extracting eigenvectors\n",
      "done in 2.490s\n",
      "PCA - Projecting to new orthonormal coordinates\n",
      "done in 0.131s\n",
      "Predicting classes on bbox Otsu\n",
      "done in 0.036s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     alicate       0.07      0.08      0.07       108\n",
      "     caderno       0.25      0.37      0.30       108\n",
      "      caneca       0.07      0.14      0.09       108\n",
      "      caneta       0.10      0.04      0.05       108\n",
      "       chave       0.15      0.17      0.16       108\n",
      "      colher       0.04      0.06      0.05       108\n",
      "        copo       0.00      0.00      0.00       108\n",
      "        faca       0.08      0.13      0.10       108\n",
      "       garfo       0.12      0.06      0.08       108\n",
      "       livro       0.19      0.07      0.11       108\n",
      "\n",
      "    accuracy                           0.11      1080\n",
      "   macro avg       0.11      0.11      0.10      1080\n",
      "weighted avg       0.11      0.11      0.10      1080\n",
      "\n",
      "[[ 9  8 20  6  6 37  0 14  6  2]\n",
      " [15 40 13  3 11 12  1  6  2  5]\n",
      " [ 8 26 15  4  7 20  0 17  3  8]\n",
      " [ 2 11 26  4 24  7  0 22  7  5]\n",
      " [20 11 24  8 18  5  0 17  2  3]\n",
      " [19  9 23  1  8  6  1 25 14  2]\n",
      " [27 10  8  4 14 15  0 18  9  3]\n",
      " [ 9 11 30  5 17 10  0 14  7  5]\n",
      " [ 6  6 32  3 10 23  0 20  7  1]\n",
      " [17 30 20  1  2  8  0 19  3  8]]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### avaliar o modelo com o dataset \"bboxOtsu\"\n",
    "###\n",
    "\n",
    "# ler metadados segmentação Otsu\n",
    "pasta1 = \"./bboxOtsu/\"\n",
    "metafile1 = \"grade.csv\"\n",
    "filename1 = pasta1 + metafile1\n",
    "df1 = pd.read_csv(filename1, sep=\";\")\n",
    "#print(df1.head(5), \"\\n\")\n",
    "\n",
    "\n",
    "# ler fotos em uma lista\n",
    "fotos1 = []\n",
    "for foto in df1[\"arquivo\"]:\n",
    "    fullname1 = pasta1 + foto\n",
    "    img1 = io.imread(fullname1)\n",
    "    fotos1.append(img1)\n",
    "\n",
    "    \n",
    "# normalizar fotos para dimensão única\n",
    "d = 100\n",
    "dim = (d, d)\n",
    "fotos2 = [resize(img1, dim) for img1 in fotos1]\n",
    "\n",
    "\n",
    "# criar arrays de predictors e outcomes\n",
    "X = [f2.flatten() for f2 in fotos2]\n",
    "y = df1[\"objeto\"]\n",
    "\n",
    "\n",
    "# calcular PCA\n",
    "n_components = 110\n",
    "\n",
    "print(\"PCA - Extracting eigenvectors\")\n",
    "t0 = time()\n",
    "\n",
    "pca = PCA(n_components=n_components,\n",
    "          svd_solver='randomized',\n",
    "          whiten=True).fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "h = d\n",
    "w = d\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "print(\"PCA - Projecting to new orthonormal coordinates\")\n",
    "t0 = time()\n",
    "\n",
    "X_pca = pca.transform(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "# avaliar o modelo com o dataset completo bboxOtsu\n",
    "print(\"Predicting classes on bbox Otsu\")\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados indicam um desempenho bastante baixo (insatisfatório) para todas as classes. Nota-se que a matriz de classificação possui elementos esparsos, não concentrados na diagonal pincipal, o que corrobora o baixo nível de acerto na classificação. O \"overall accuracy\" ficou em 0.13.\n",
    "\n",
    "A equipe acredita que a principal causa raiz está no fundo escolhido para as fotos originais, em especial o as fotos com \"fundo xadrez\" e \"fundo mickey\". Por serem fundos bastante estampados, os padrões destes fundos em muitas fotos se confundiu com o objeto segmentado, o que gerou uma imagem distorcida da classe sob análise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
